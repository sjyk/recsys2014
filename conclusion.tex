\section{Future Work}
The study of social influence in the CRC has several interesting directions for future work.
We would like to run user studies comparing a control group that did not see the median grade, 
a treatment group who saw an incorrect median grade (as in the Asch experiments), and test the effect of an increased delay in revealing the median grade.
We believe that the results from such a study would help inform the design of rating systems.
 
We also want to extend our work to quantify the role of social influence in textual data. 
The California Report Card collects textual suggestions from participants in addition to the quantitative ratings on political issues. 
Participants are encouraged to read the responses of others before leaving a suggestion of their own.
We suspect that this may lead to a bias in the topics discussed by participants, and we would like to explore how similar non-parametric models can be extended to textual data.
We hypothesize that unlike this work, participants may try to differentiate their ideas from ones they have already ready.
\section{Conclusion}
Participants in almost all recommender systems see mean, median, or other aggregate statistics before leaving their own ratings.
We studied whether seeing the median rating would bias participants towards leaving grades closer to the median in a new platform, the California Report Card, which allows participants to revise their ratings after seeing the median value.
In the CRC, we found that not only did 35\% of participants revise their grades, but those revisions were significantly directed towards the median grade.
We modeled these changes with polynomial function, whose degree we chose optimally using the Bayes Information Criterion.
We showed how this model could not only accurately predict final grades given an initial grade and the observed median, but also could be inverted to infer a intial grade from a final one; mitigating the effects of social influence bias.
Few existing tools collect pairs of ratings, and our results suggest that the pairs give valuable insight about initial ``unbiased" perceptions, the magnitude of social influence, and can train for accurate corrective models for use on past data.
Our tests for determining the existence of social influence and predicting its effects can help inform the design of recommendation systems through better tuned similarity measures of participants.


