\section{Predicting Grade Changes}
\label{changemod}
In the previous two sections, we proposed a technique to test the significance of social influence in the grades that changed.
In this section, we build a model to describe the relationship between the variables in the 3-tuple ($g_i[j]$, $m[j]$, $g_f[j]$).
In other words, given a participant's current grade, the median they observed, can we predict the final grade?

\subsection{Modeling Changes}
Previous work, suggests that social influence is not a homogeneous bias, namely, positive influences are different from negative influences.
In Muchnik et al. \cite{muchnik2013social}, they found that when they positively treated posts with higher up-vote counts it lead to a significant increase in the likelihood of additional up votes (32\% more likely). 
On the other hand, they argue negative treatments inspired correction behavior; where some participants wanted to correct what they felt was an incorrect score. 
They found that this also increased the likelihood of up-voting (88\% more likely); as opposed to the conforming response which would be increased down-votes.

These results suggest that the effects of viewing median grades can be non-linear and are very context/question dependent.
Similar to the previous section where we applied non-parametric tests that did not make a strong assumption about the distribution of the data, we propose a information theoretic polynomial function search that does not make strong assumptions about the nature of the relationship.
Conditioned on the event that the participant changes their grade, we learn a polynomial relationship to predict the final grade given the observed median and initial grade.
% the space of all polynomial models is fairly exhaustive, we acknowledge that this model can only fit curves that are continuous and smooth.

Let $f\in \mathcal{P}^k$ be a polynomial of degree $k$.
The square loss of $f$, is the error in predicting $g_f[j] - g_i[j]$ from $f(m[j] - g_i[j])$:
\begin{equation}
\mathcal{L}(X_c;f,k) = \sum_j ((g_f[j] - g_i[j]) - f(m[j] - g_i[j]))^2 
\end{equation}
For a given $k$, the best-fit polynomial minimizes this square-loss:
\begin{equation}
f^*_k =\arg \min_f \mathcal{L}(X_c;f,k)
\end{equation}
For a given $k$, this problem can be solved with least squares.
To search over the space of polynomial models, we apply a well-studied technique called the Bayesian Information Criterion (BIC) \cite{schwarz1978estimating,burnham2002model}.
This technique converts the optimization problem into a penalized problem that jointly optimizes over the ``complexity parameter" $k$.
This penalty can be interpreted as bias towards lower degree models, in other words, an Occam's Razor prior belief. 
Cross-validation is an alternate method to empirically determine optimal model, and in practice, they give very similar results.
BIC, however, is derived through maximum likelihood estimate and is not an empirical so the learned model has a notion of optimality conditioned on the BIC prior belief.

Thus, we reformulate the optimization problem in the following way to incorporate the BIC penalty:
\begin{equation}
\arg \min_{f,k} |X_c|\log(\mathcal{L}(X_c;f,k)) + k\log(|X_c|)
\end{equation}
The resulting optimal polynomial will tell how the regression affects varies as a function of $m[j] - g_i[j]$ while controlling for over-fitting to our data.
\subsection{Applications in Existing Recommender Systems}
Existing systems may not collect pairs of initial and final ratings, yet may still be affected by social influence bias.
To address this problem, we can collect training data \emph{with} the pairs of ratings; an initial rating with the median/mean hidden and a final one after revision.
Collecting a training set of initial and final ratings for recommender systems with a large number of items is increasingly viable through crowdsourcing platforms such as Amazon Mechanical Turk.
We define the \emph{inverse model} as the polynomial/BIC model that infers initial grades from the final ones.
We modify and invert the loss function with the dependent variable defined as $g_f[j]$ and the independent variable $m[j] - g_i[j]$.
We optimize using the BIC over this loss, and calculate the optimal polynomial $f^{-1}$, which maps final grades to observed differences with the median grade.
Let $q(j) = m[j] - f^{-1}(g_f[j])$ be the optimal \emph{inverse model} as it predicts the initial grade for participant $j$.
$q(j)$, a predicted initial grade, can be the input to our recommendation algorithm.
Even for past participants not in the training set, we can predict a hypothetical ``initial" grade using $q$, thus mitigating the effect of social influence bias.


